{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14a2f215-03fc-43a9-ba03-c4b202b61f07",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Window Functions"
    }
   },
   "outputs": [],
   "source": [
    "#https://sparkbyexamples.com/pyspark/pyspark-window-functions/\n",
    "\n",
    "row_number() => Returns a sequential number starting from 1 within a window partition.  \n",
    "rank() => Returns the rank of rows within a window partition, with gaps.  \n",
    "percent_rank() => Returns the percentile rank of rows within a window partition.  \n",
    "dense_rank() => Returns the rank of rows within a window partition without any gaps (Rank() returns rank with gaps).  \n",
    "ntile(n) => Returns the ntile ID in a window partition.  \n",
    "cume_dist() => Returns the cumulative distribution of values within a window partition.  \n",
    "lag(e, offset) => Retrieves the value of a column from a preceding row within the same window.  \n",
    "lag(col, offset) => Same as above but explicitly takes the column name.  \n",
    "lag(col, offset, default) => Same as above but uses default value if preceding row doesn't exist.  \n",
    "lead(col, offset) => Retrieves the value of a column from a succeeding row within the same window.  \n",
    "lead(col, offset, default) => Same as above but uses default value if succeeding row doesn't exist.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11ce4113-14bc-4c4a-baf6-b138bf1bb511",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "All Functions"
    }
   },
   "outputs": [],
   "source": [
    "# https://sparkbyexamples.com/pyspark/pyspark-sql-functions/#partition\n",
    "\n",
    "row_number() => Returns a sequential number starting from 1 within a window partition.\n",
    "rank() => Returns the rank of rows within a window partition, with gaps.\n",
    "percent_rank() => Returns the percentile rank of rows within a window partition.\n",
    "dense_rank() => Returns the rank of rows within a window partition without gaps. rank() returns with gaps.\n",
    "ntile(n) => Returns the ntile id in a window partition.\n",
    "cume_dist() => Returns the cumulative distribution of values within a window partition.\n",
    "lag(column, offset, default) => Retrieves the value from a preceding row in the same window.\n",
    "lead(column, offset, default) => Retrieves the value from a succeeding row in the same window.\n",
    "\n",
    "---- Aggregations ----\n",
    "count(col) => Counts the number of non-null rows.\n",
    "countDistinct(col) => Counts distinct non-null values.\n",
    "sum(col) => Returns the sum of values.\n",
    "avg(col) => Returns the average of values.\n",
    "min(col) => Returns the minimum value.\n",
    "max(col) => Returns the maximum value.\n",
    "\n",
    "---- String Functions ----\n",
    "concat(col1, col2, ...) => Concatenates multiple columns into one.\n",
    "concat_ws(sep, col1, ...) => Concatenates columns with a separator.\n",
    "upper(col) => Converts string to upper case.\n",
    "lower(col) => Converts string to lower case.\n",
    "trim(col) => Removes both leading and trailing spaces.\n",
    "ltrim(col) => Removes leading spaces.\n",
    "rtrim(col) => Removes trailing spaces.\n",
    "length(col) => Returns the length of a string.\n",
    "substr(col, pos, len) => Returns substring from position with length.\n",
    "instr(col, substring) => Returns position of substring.\n",
    "regexp_replace(col, pattern, replacement) => Replaces matching substrings.\n",
    "regexp_extract(col, pattern, idx) => Extracts matching substring by regex.\n",
    "\n",
    "---- Date/Time Functions ----\n",
    "current_date() => Returns the current date.\n",
    "current_timestamp() => Returns the current timestamp.\n",
    "date_format(date, fmt) => Formats date to given pattern.\n",
    "year(date) => Returns the year.\n",
    "month(date) => Returns the month.\n",
    "dayofmonth(date) => Returns the day of month.\n",
    "dayofweek(date) => Returns the day of week.\n",
    "dayofyear(date) => Returns the day of year.\n",
    "weekofyear(date) => Returns the week number of year.\n",
    "hour(ts) => Returns hour from timestamp.\n",
    "minute(ts) => Returns minute from timestamp.\n",
    "second(ts) => Returns second from timestamp.\n",
    "add_months(date, n) => Adds n months to date.\n",
    "date_add(date, days) => Adds days to date.\n",
    "date_sub(date, days) => Subtracts days from date.\n",
    "last_day(date) => Returns last day of month for date.\n",
    "next_day(date, dayOfWeek) => Returns next date matching given day of week.\n",
    "unix_timestamp(col) => Converts time to UNIX timestamp.\n",
    "from_unixtime(ts) => Converts UNIX timestamp to string date.\n",
    "\n",
    "---- Array Functions ----\n",
    "array(col1, col2, ...) => Creates an array column from multiple columns.\n",
    "size(col) => Returns the length of an array or map.\n",
    "explode(col) => Creates a new row for each element in array.\n",
    "split(col, regex) => Splits string into array by regex.\n",
    "array_contains(col, value) => Checks if array contains a value.\n",
    "\n",
    "---- Map & Struct Functions ----\n",
    "create_map(key, value, ...) => Creates a map from key/value pairs.\n",
    "get_json_object(col, path) => Extracts JSON value by JSON path.\n",
    "from_json(col, schema) => Parses JSON string to struct/array.\n",
    "to_json(col) => Converts struct/array/map to JSON string.\n",
    "\n",
    "---- Null Handling ----\n",
    "isnull(col) => Checks if column is NULL.\n",
    "isnan(col) => Checks if column is NaN.\n",
    "na.fill(value, subset) => Fills nulls in DataFrame.\n",
    "na.drop(subset) => Drops rows with nulls in subset columns.\n",
    "\n",
    "---- Math Functions ----\n",
    "pow(col, n) => Raises value to the power of n.\n",
    "sqrt(col) => Returns square root.\n",
    "log(col) => Returns natural log (base e).\n",
    "log10(col) => Returns log base 10.\n",
    "exp(col) => Returns e raised to value.\n",
    "\n",
    "---- Conditional Functions ----\n",
    "when(condition, value) => Returns value when condition is true.\n",
    "otherwise(value) => Specifies value when when() condition is false.\n",
    "greatest(col1, col2, ...) => Returns largest value among columns.\n",
    "least(col1, col2, ...) => Returns smallest value among columns.\n",
    "\n",
    "---- Window Aggregates ----\n",
    "collect_list(col) => Returns list of values within group/window.\n",
    "collect_set(col) => Returns unique set of values within group/window.\n",
    "first(col, ignorenulls) => Returns first value in group/window.\n",
    "last(col, ignorenulls) => Returns last value in group/window."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark_Functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
